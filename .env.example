# =========================================================
# App runtime
# =========================================================
APP_ENV=development
DEBUG=false
PORT=8080

# =========================================================
# Local model routing
# development/testing -> QWEN_MODEL_LOCAL
# production fallback default -> QWEN_MODEL_PRODUCTION
# =========================================================
OLLAMA_BASE_URL=http://localhost:11434
QWEN_MODEL_LOCAL=qwen2.5:0.5b
QWEN_MODEL_PRODUCTION=qwen2.5:7b

# =========================================================
# Production primary backend (vLLM)
# =========================================================
VLLM_BASE_URL=http://vllm-service:8000/v1
VLLM_MODEL=Qwen/Qwen-7B

# =========================================================
# Script generation guardrails
# Always require at least SCRIPT_MIN_CHARS chars
# Retry primary SCRIPT_PRIMARY_ATTEMPTS times before fallback
# =========================================================
SCRIPT_MIN_CHARS=40
SCRIPT_PRIMARY_ATTEMPTS=2

# =========================================================
# LLM fallback
# backend: ollama | vllm | zhipu
# =========================================================
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_BACKEND=zhipu
LLM_FALLBACK_BASE_URL=http://localhost:11434
LLM_FALLBACK_MODEL=qwen2.5:0.5b

# =========================================================
# Zhipu fallback (used when LLM_FALLBACK_BACKEND=zhipu)
# =========================================================
ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4
ZHIPU_API_KEY=your_zhipu_api_key
ZHIPU_MODEL=glm-4-flash
