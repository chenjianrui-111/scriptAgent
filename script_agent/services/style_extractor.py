"""
é£æ ¼æå–æœåŠ¡ - ä»ç”¨æˆ·é‡‡çº³çš„è¯æœ¯ä¸­æå–é£æ ¼ç‰¹å¾

ä¸‰ç®¡é½ä¸‹:
  1. ä»é‡‡çº³è¯æœ¯ç»Ÿè®¡åˆ†æ (è§„åˆ™+NLP)
  2. ä»ç”¨æˆ·ä¿®æ”¹å¯¹æ¯”æ¨æ–­åå¥½ (diffåˆ†æ)
  3. ä»ç”¨æˆ·æ˜ç¡®è¡¨è¾¾ç†è§£æ„å›¾ (LLMæå–)

æ›´æ–°ç­–ç•¥: åŠ æƒèåˆ (æ–°30% + æ—§70%, å¸¦æ—¶é—´è¡°å‡)
"""

import re
import logging
from collections import Counter
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from script_agent.models.context import (
    SessionContext, StyleProfile, ConversationTurn,
)

logger = logging.getLogger(__name__)


@dataclass
class CatchphraseResult:
    phrase: str
    category: str
    frequency: int
    confidence: float


@dataclass
class ExtractedStyle:
    """æå–å‡ºçš„é£æ ¼ç‰¹å¾"""
    tone: str = ""
    formality_level: float = 0.5
    catchphrases: List[str] = field(default_factory=list)
    avg_sentence_length: float = 20.0
    punctuation_style: str = "normal"
    selling_point_style: str = "direct"
    interaction_frequency: float = 0.5
    humor_level: float = 0.3
    sample_count: int = 0
    confidence: float = 0.5


class CatchphraseExtractor:
    """å£å¤´ç¦…æå–å™¨"""

    KNOWN_PATTERNS = {
        "addressing": [
            r"å§å¦¹ä»¬?", r"å®å­ä»¬?", r"å®¶äººä»¬?", r"å®å®ä»¬?",
            r"å°ä»™å¥³ä»¬?", r"é›†ç¾ä»¬?", r"å…„å¼Ÿä»¬?", r"æœ‹å‹ä»¬?",
        ],
        "emphasis": [
            r"çœŸçš„", r"ç»äº†", r"çˆ±äº†", r"yyds", r"ç»ç»å­",
        ],
        "recommendation": [
            r"å¿…å…¥", r"å¿…ä¹°", r"é—­çœ¼å…¥", r"å¼ºæ¨", r"å®‰åˆ©",
        ],
        "modal": [
            r"å•Š+", r"å‘€+", r"å“¦+", r"å˜¿+", r"å“ˆ+",
        ],
    }

    def __init__(self):
        self.compiled = {
            cat: [re.compile(p) for p in patterns]
            for cat, patterns in self.KNOWN_PATTERNS.items()
        }

    def extract(self, texts: List[str]) -> List[CatchphraseResult]:
        all_matches: List[Tuple[str, str]] = []
        for text in texts:
            for cat, patterns in self.compiled.items():
                for pat in patterns:
                    for m in pat.finditer(text):
                        all_matches.append((m.group(), cat))

        freq = Counter(phrase for phrase, _ in all_matches)
        results = []
        for phrase, count in freq.most_common(20):
            if count >= 2 or (texts and count / len(texts) >= 0.3):
                cat = next(
                    (c for p, c in all_matches if p == phrase), "other"
                )
                results.append(CatchphraseResult(
                    phrase=phrase, category=cat,
                    frequency=count,
                    confidence=min(count / max(len(texts), 1), 1.0),
                ))
        return results


class FormalityAnalyzer:
    """æ­£å¼åº¦åˆ†æ"""

    CASUAL_MARKERS = ["å•Š", "å‘€", "å“¦", "å˜¿", "å“ˆ", "ï¼", "~", "å“‡", "å˜»"]
    FORMAL_MARKERS = ["å°Šæ•¬çš„", "æ‚¨å¥½", "ç‰¹æ­¤", "å»ºè®®æ‚¨", "å€¼å¾—å…³æ³¨"]

    def analyze(self, text: str) -> float:
        """è¿”å›æ­£å¼åº¦ 0(å£è¯­) - 1(æ­£å¼)"""
        casual = sum(text.count(m) for m in self.CASUAL_MARKERS)
        formal = sum(text.count(m) for m in self.FORMAL_MARKERS)
        total = max(casual + formal, 1)
        return formal / total


class StyleExtractor:
    """é£æ ¼ç‰¹å¾æå– - ç»¼åˆè§„åˆ™+NLP"""

    def __init__(self):
        self.catchphrase_extractor = CatchphraseExtractor()
        self.formality_analyzer = FormalityAnalyzer()

    def extract_from_texts(self, texts: List[str]) -> ExtractedStyle:
        """ä»å¤šä¸ªé‡‡çº³è¯æœ¯ä¸­æå–é£æ ¼"""
        if not texts:
            return ExtractedStyle()

        # 1. å£å¤´ç¦…
        catchphrases = self.catchphrase_extractor.extract(texts)
        top_phrases = [cp.phrase for cp in catchphrases[:5]]

        # 2. æ­£å¼åº¦
        formality_scores = [self.formality_analyzer.analyze(t) for t in texts]
        avg_formality = sum(formality_scores) / len(formality_scores)

        # 3. å¥å­é•¿åº¦
        all_sentences = []
        for text in texts:
            sents = re.split(r'[ã€‚ï¼ï¼Ÿ~\n]', text)
            all_sentences.extend(s for s in sents if len(s) > 2)
        avg_sent_len = (
            sum(len(s) for s in all_sentences) / len(all_sentences)
            if all_sentences else 20.0
        )

        # 4. æ ‡ç‚¹é£æ ¼
        total_chars = sum(len(t) for t in texts)
        exclaim_count = sum(t.count("ï¼") + t.count("!") for t in texts)
        wave_count = sum(t.count("~") for t in texts)
        if total_chars > 0:
            exclaim_ratio = exclaim_count / total_chars
            punct_style = (
                "enthusiastic" if exclaim_ratio > 0.03
                else "calm" if exclaim_ratio < 0.005
                else "normal"
            )
        else:
            punct_style = "normal"

        # 5. äº’åŠ¨é¢‘ç‡
        interaction_markers = ["?", "ï¼Ÿ", "å—", "å‘¢", "ç‚¹èµ", "å…³æ³¨"]
        interaction_count = sum(
            sum(t.count(m) for m in interaction_markers) for t in texts
        )
        interaction_freq = min(interaction_count / max(len(texts), 1) / 5, 1.0)

        # 6. å¹½é»˜åº¦ (ç®€åŒ–: çœ‹emojiå’Œæç¬‘è¯æ±‡é¢‘ç‡)
        humor_markers = ["å“ˆå“ˆ", "ç¬‘", "ğŸ˜‚", "ğŸ¤£", "æç¬‘", "æ®µå­"]
        humor_count = sum(
            sum(t.count(m) for m in humor_markers) for t in texts
        )
        humor_level = min(humor_count / max(len(texts), 1) / 3, 1.0)

        # 7. è¯­æ°”æ¨æ–­
        if avg_formality < 0.3:
            tone = "æ´»æ³¼å£è¯­"
        elif avg_formality > 0.7:
            tone = "æ­£å¼ä¸“ä¸š"
        else:
            tone = "è‡ªç„¶äº²å’Œ"

        return ExtractedStyle(
            tone=tone,
            formality_level=avg_formality,
            catchphrases=top_phrases,
            avg_sentence_length=avg_sent_len,
            punctuation_style=punct_style,
            interaction_frequency=interaction_freq,
            humor_level=humor_level,
            sample_count=len(texts),
            confidence=min(0.5 + len(texts) * 0.05, 0.95),
        )


class ProfileUpdater:
    """
    ç”»åƒæ›´æ–°å™¨ - åŠ æƒèåˆç­–ç•¥
    æ–°æå–30% + ç°æœ‰ç”»åƒ70% (å¸¦æ—¶é—´è¡°å‡)
    """

    NEW_WEIGHT = 0.3
    EXISTING_WEIGHT = 0.7

    def merge(self, existing: StyleProfile,
              extracted: ExtractedStyle) -> StyleProfile:
        """èåˆæ–°æå–çš„é£æ ¼åˆ°ç°æœ‰ç”»åƒ"""
        w_new = self.NEW_WEIGHT
        w_old = self.EXISTING_WEIGHT

        merged = StyleProfile(
            influencer_id=existing.influencer_id,
            tone=extracted.tone if extracted.confidence > existing.confidence else existing.tone,
            formality_level=round(
                existing.formality_level * w_old + extracted.formality_level * w_new, 3
            ),
            catchphrases=self._merge_catchphrases(
                existing.catchphrases, extracted.catchphrases
            ),
            avg_sentence_length=round(
                existing.avg_sentence_length * w_old + extracted.avg_sentence_length * w_new, 1
            ),
            punctuation_style=extracted.punctuation_style,
            interaction_frequency=round(
                existing.interaction_frequency * w_old + extracted.interaction_frequency * w_new, 3
            ),
            humor_level=round(
                existing.humor_level * w_old + extracted.humor_level * w_new, 3
            ),
            sample_count=existing.sample_count + extracted.sample_count,
            confidence=min(existing.confidence + 0.05, 0.95),
            last_updated=datetime.now(),
            version=existing.version + 1,
        )
        return merged

    def _merge_catchphrases(self, old: List[str],
                             new: List[str]) -> List[str]:
        """åˆå¹¶å£å¤´ç¦…, ä¿ç•™é¢‘ç‡æœ€é«˜çš„"""
        seen = set()
        result = []
        for phrase in new + old:
            if phrase not in seen:
                seen.add(phrase)
                result.append(phrase)
        return result[:10]
